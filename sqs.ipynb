{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "from hashlib import sha224\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from redis import Redis\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__) # \"__name__\"를 하면, root log는 제외시키고, 이 모듈 내에서 발생한 로그만 포함시킴. 없으면 requests 모듈에서 생긴 로그, boto3에서 생긴 로그 등이 포함되어 버림 그래서 지저분해짐\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('{\"method\" : \"CRAWLING\", \"time\" : \"%(asctime)s\", \"level\" : \"%(levelname)s\", \"message\" : \"%(message)s\"}')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "sqs = boto3.resource('sqs')\n",
    "try:\n",
    "    queue = sqs.get_queue_by_name(QueueName='nvmids')\n",
    "except:\n",
    "    queue = sqs.create_queue(QueueName='nvmids',Attributes=\n",
    "                            {\n",
    "                                \"MaximumMessageSize\":\"4096\",\n",
    "                                \"VisibilityTimeout\":\"10\",\n",
    "                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQS 관련된 Parameter\n",
    "\n",
    "| 항목  | 의미  |\n",
    "|----|----|\n",
    "| DefaultVisibleTimeout | SQS에서 메시지는 특정 Component에 전달된 뒤, 자동으로 삭제 되지 않는데, 그 때문에 중복된 메시지를 전달받을 수 있음. 그래서 한번 전달된 메시지는 visible timeout에 설정된 일정시간 동안은 다시 전달되지 않도록 하고 있음. 이러한 메시지들의 상태를 **inflight**라고 표현함.|\n",
    "| MessageRetentionPeriod | 메시지 생명주기 / 1분부터 최대 14일까지 지정할 수 있음 |\n",
    "| Maximum Message Size | 메시지 최대 크기 최대 256Kbytes까지 가능 |\n",
    "| Delivery Delay | 새로운 메시지가 전달되는 초기 지연 시간. 0초~900초(15분)까지 설정 가능. |\n",
    "| Receive Message Wait Time | Long Polling을 활성화 함, 0~20초까지 가능 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Redis에 item 정보 담기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis = Redis(host='localhost',port=6379)\n",
    "item_df = pd.read_csv(\"data/sample_item.csv\",sep=\"▒\",dtype=str,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in item_df.iterrows():\n",
    "    # set of item data about nvmid\n",
    "    redis.hset(\"item\",row.nv_mid,json.dumps(row.to_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SQS(simple Queue Service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQS에 메시지 보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvmid의 집합\n",
    "nvmids = [key.decode('utf-8') for key in redis.hkeys('item')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvmids에 보내는 메시지 형식\n",
    "nvmid_message = lambda nvmid, item, page : {\n",
    "    \"Id\" : nvmid,\n",
    "    \"MessageBody\": item,\n",
    "    \"MessageAttributes\" : {\n",
    "        \"Page\" : {\n",
    "            \"StringValue\" : page,\n",
    "            \"DataType\" : \"Number\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvmid queue에 Bulk Insert하기 \n",
    "Entries = []\n",
    "start = time.time()\n",
    "for nvmid in nvmids:\n",
    "    item = redis.hget(\"item\",nvmid).decode('utf-8')\n",
    "    Entries.append(nvmid_message(nvmid,item,\"1\"))\n",
    "    if len(Entries) == 10:\n",
    "        queue.send_messages(Entries=Entries)\n",
    "        Entries=[]\n",
    "if len(Entries) > 0:\n",
    "    queue.send_messages(Entries=Entries)\n",
    "    Entries=[]\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQS에서 메시지 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = queue.receive_messages(AttributeNames=[\"All\"],\n",
    "                                MessageAttributeNames=['Page'],\n",
    "                                MaxNumberOfMessages=1,\n",
    "                                WaitTimeSeconds=3)\n",
    "if len(messages)>0:\n",
    "    msg = messages[0]    \n",
    "    if msg.message_attributes is not None:\n",
    "        item_row = json.loads(msg.body)\n",
    "        page = msg.message_attributes.get('Page').get(\"StringValue\",\"1\")\n",
    "    else:\n",
    "        page = \"1\"\n",
    "    msg.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crawl and analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://search.shopping.naver.com/detail/review_list.nhn\"\n",
    "headers = {\n",
    "    \"accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"accept-encoding\":\"gzip, deflate, br\",\n",
    "    \"accept-language\":\"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    \"user-agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"\n",
    "}\n",
    "params = {\n",
    "   \"nvMid\":10010250511,\n",
    "    \"page\": 1,\n",
    "    \"reviewSort\": \"registration\",\n",
    "    \"reviewType\": \"all\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['nvMid'] = item_row['nv_mid']\n",
    "params['page'] = page\n",
    "\n",
    "res = requests.post(base_url,params=params,headers=headers,timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 고유 명사 수 세기 (얼마나 단어에 의미 있는 것들이 존재하는가에 대한 지표)\n",
    "twitter = Twitter()\n",
    "count_unique_nouns = lambda text : len(set(twitter.nouns(text)))\n",
    "\n",
    "# 2. 리뷰의 고유 ID 지정해주기\n",
    "convert_hash = lambda text : sha224(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# 3. 리뷰 별 Tag값 지정하기\n",
    "score_df = pd.read_csv(\"data/score.csv\",sep=\"▒\",engine='python')\n",
    "def calculate_tag(threshold,review):\n",
    "    # threshold : tag score의 mimimum value\n",
    "    # 리뷰 내 토큰 집합을 가져옴\n",
    "    tokens = set(twitter.morphs(review,stem=True,norm=True))\n",
    "    # score가 있는 토큰들을 모은 후, type별 score을 매김\n",
    "    results = score_df.loc[score_df.token.isin(tokens),['score','type']].groupby('type').sum()\n",
    "    # index\n",
    "    return results[results.score >=threshold].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsObj = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "if len(bsObj.find_all(\"div\",{'class':'atc_area'})) == 0 :\n",
    "    logger.info('no review ... url {}'.format(res.url))\n",
    "rows = []    \n",
    "for atc_area in bsObj.find_all(\"div\",{'class':'atc_area'}):\n",
    "    row = item_row.copy()\n",
    "    try:\n",
    "        title_expr =    atc_area.p.text\n",
    "        row[\"review_title\"] = re.sub(\"[\\n\\t]\",\"\",title_expr).strip()\n",
    "    except:\n",
    "        logger.warning(\"info is missing... url : {}\".format(res_url))\n",
    "        row['review_title'] = \"\"\n",
    "    try:\n",
    "        atc_expr = atc_area.find(\"div\",{'class':'atc'}).text\n",
    "        row[\"review_atc\"] = re.sub(\"[\\n\\t]\",\"\",atc_expr).strip()\n",
    "    except:\n",
    "        logger.error('article is missing... url : {}'.format(res_url))\n",
    "        continue\n",
    "    try:\n",
    "        row[\"review_grade\"] = atc_area.find(\"span\",{'class':'curr_avg'}).text\n",
    "    except:\n",
    "        logger.warning('grade is missing... url : {}'.format(res_url))\n",
    "        row['review_grade'] = \"0\"\n",
    "    try:\n",
    "        date_expr = atc_area.find(\"span\",{'class':'date'}).text\n",
    "        row[\"review_date\"] = re.sub(\"[^\\d.]\",\"\",date_expr)\n",
    "    except:\n",
    "        logger.warning('date is missing... url : {}'.format(res_url))\n",
    "        row['review_date'] = datetime.strftime(datetime.now(),format=\"%Y.%m.%d.\")\n",
    "    try:\n",
    "        row[\"review_mall\"] = atc_area.find(\"span\",{'class':'path'}).text\n",
    "    except:\n",
    "        logger.warning('path is missing... url : {}'.format(res_url))\n",
    "        row['review_mall'] = \"\"\n",
    "        \n",
    "    row['review_id'] = convert_hash(row[\"nv_mid\"])+\\\n",
    "                convert_hash(row[\"review_atc\"]+row[\"review_title\"]+row['review_date'])\n",
    "    row['review_accuracy'] = count_unique_nouns(row['review_atc'])\n",
    "    row['review_tag'] = list(calculate_tag(0.5,row['review_atc']))\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insert document into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_index_name = \"item_table\"\n",
    "review_index_name = \"review_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is Okay\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(host=\"localhost\")\n",
    "if es.ping():\n",
    "    # Check Elasticsearch is operating\n",
    "    print(\"Elasticsearch is Okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action(_index,_type):\n",
    "    def _generate_action(_id, _source):\n",
    "        return {\n",
    "            \"_index\"  : _index,\n",
    "            \"_type\"   : _type,\n",
    "            \"_id\"     : _id,\n",
    "            \"_source\" : _source\n",
    "        }\n",
    "    return _generate_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"items\" index exists\n"
     ]
    }
   ],
   "source": [
    "if es.indices.exists(item_index_name):\n",
    "    print('\"items\" index exists')\n",
    "#     if delete_index:\n",
    "#         es.indices.delete(item_index_name, ignore=[400,404])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
